{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"HW1_MeganYiu.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XXrHqZ_R3EfR"},"source":["# Homework 1 Due Date -8th Sep (11:59 pm)\n","\n","\n","Submissions: Please submit .ipynb file and pdf file to eLearning"]},{"cell_type":"markdown","metadata":{"id":"1ryX6lIDPnBQ"},"source":["Megan Yiu - mny170000"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-01-22T19:57:47.188990Z","start_time":"2019-01-22T19:57:46.107420Z"},"id":"9hCgUyxQ3EfS"},"source":["import torch\n","import numpy as np\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2TU6l0nC3EfW"},"source":["## Question 1. Speedtest for vectorization - 1 Point\n","\n","Your goal is to measure the speed of linear algebra operations for different levels of vectorization.\n","\n","1. Construct two matrices $A$ and $B$ with Gaussian random entries of size $1024 \\times 1024$. \n","1. Compute $C = A B$ using matrix-matrix operations and report the time. (Hint: Use torch.mm)\n","1. Compute $C = A B$, treating $A$ as a matrix but computing the result for each column of $B$ one at a time. Report the time. (hint use torch.mv inside a for loop)\n","1. Compute $C = A B$, treating $A$ and $B$ as collections of vectors. Report the time. (Hint: use torch.dot inside nested for loop)"]},{"cell_type":"code","metadata":{"id":"wkKjtX0HH2wz"},"source":["## Solution 1\n","torch.manual_seed(42)\n","# your code here\n","A= torch.randn(1024, 1024)\n","B= torch.randn(1024, 1024)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSMH_j5OD2ZB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118637249,"user_tz":300,"elapsed":5,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"83966a6b-5c27-435d-f7a8-b2528eff4faa"},"source":["## Solution 2\n","start=time.time()\n","\n","# your code here\n","torch.mm(A, B)\n","print(\"Matrix by matrix: \" + str(time.time()-start) + \" seconds\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix by matrix: 0.07364797592163086 seconds\n"]}]},{"cell_type":"code","metadata":{"id":"-tU8yGBP-Crk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118640078,"user_tz":300,"elapsed":265,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"69c5333e-37dc-4af9-9d2c-a762443b5d8a"},"source":["## Solution 3\n","C= torch.empty(1024,1024)\n","start = time.time()\n","iterations = 0;\n","\n","# your code here\n","for col in range(B.shape[1]):\n","  C[:,col] = torch.mv(A, B[:,col])\n","\n","print(\"Matrix by vector: \" + str(time.time()-start) + \" seconds\") "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix by vector: 0.2188282012939453 seconds\n"]}]},{"cell_type":"code","metadata":{"id":"MFgJCFf6DUFK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118663021,"user_tz":300,"elapsed":20894,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"bdf13519-1c39-477f-a129-559e784ce3a2"},"source":["## Solution 4\n","C= torch.empty(1024,1024)\n","start = time.time()\n","\n","# your code here\n","for row in range(A.shape[0]):\n","  for col in range(B.shape[1]):\n","      C[row, col] = torch.dot(A[row,:],B[:,col])\n","\n","print(\"vector by vector: \" + str(time.time()-start) + \" seconds\")  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["vector by vector: 20.376437425613403 seconds\n"]}]},{"cell_type":"markdown","metadata":{"id":"TtYsJM4mJNdE"},"source":["## Question 2 : Redo Question 1 by using GPU - 1 Point"]},{"cell_type":"markdown","metadata":{"id":"fxJ1UlTf3Efb"},"source":["##Using GPUs\n","\n","How to use GPUs in Google Colab<br>\n","In Google Colab -- Go to Runtime Tab at top -- select change runtime type -- for hardware accelartor choose GPU"]},{"cell_type":"code","metadata":{"id":"9K0dZeN9P_8E"},"source":["import torch\n","import numpy as np\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6ilpofMIe1e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118667210,"user_tz":300,"elapsed":309,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"90766aef-bd36-490d-b02f-308f83e9624a"},"source":["# Check if GPU is availaible\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","metadata":{"id":"4XMhjifbJcu0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118678281,"user_tz":300,"elapsed":9427,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"6f63c391-569f-43c4-dda5-07efba7c180c"},"source":["## Solution 1\n","torch.manual_seed(42)\n","A= torch.randn((1024, 1024),device=device)\n","B= torch.randn((1024, 1024),device=device)\n","\n","#check device of each tensor\n","print(A.device)\n","print(B.device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","cuda:0\n"]}]},{"cell_type":"code","metadata":{"id":"pn-ZKI7sK9Oh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118681135,"user_tz":300,"elapsed":309,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"18c2ac92-d332-4226-934d-dbb630a07bcc"},"source":["## Solution 2\n","start=time.time()\n","\n","# your code here\n","C = torch.mm(A,B)\n","print(\"Matrix by matrix: \" + str(time.time()-start) + \" seconds\")\n","#print(C)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix by matrix: 0.009042024612426758 seconds\n"]}]},{"cell_type":"code","metadata":{"id":"GcHPGEitLL8i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118683805,"user_tz":300,"elapsed":326,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"45fc9991-88b5-4afe-9a75-68d2cc21fd4e"},"source":["## Solution 3\n","C= torch.empty((1024, 1024),device=device)\n","start = time.time()\n","\n","# your code here\n","for col in range(B.shape[1]):\n","  column = B[:,col]\n","  C[:,col] = torch.mv(A, column)\n","\n","print(\"Matrix by vector: \" + str(time.time()-start) + \" seconds\")  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix by vector: 0.048941612243652344 seconds\n"]}]},{"cell_type":"code","metadata":{"id":"wZ5LWSa2Lrdw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118774831,"user_tz":300,"elapsed":56319,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"0194198b-f617-4247-9d91-6e7872401b9e"},"source":["## Solution 4\n","D= torch.empty((1024, 1024),device=device)\n","start = time.time()\n","\n","# your code here\n","for row in range(A.shape[0]):\n","  for col in range(B.shape[1]):\n","      D[row, col] = torch.dot(A[row,],B[:,col])\n","\n","print(\"vector by vector: \" + str(time.time()-start) + \" seconds\")  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["vector by vector: 56.00712466239929 seconds\n"]}]},{"cell_type":"markdown","metadata":{"id":"LQ9ufe5u3Eff"},"source":["## Question 3. PyTorch Tensor and NumPy - 1.5 Points\n","\n","Your goal is to measure the speed penalty between PyTorch Tensors and Python when converting data between both. We are going to do this as follows:\n","\n","1. Create two Gaussian random matrices $A, B$ of size $10000 \\times 10000$ in PyTorch. \n","1. Compute a vector $\\mathbf{c} \\in \\mathbb{R}^{10000}$ where $c_i = \\|A B_{i\\cdot}\\|^2$ where $\\mathbf{c}$ is a **NumPy** vector.\n","\n","<br>**Hint : each elemnt of $c_i$ can be computed as \n","   \n","\n","```\n","torch.norm(torch.mv(A,B[:,i]))**2\n","```\n","\n","To see the difference in speed due to Python perform the following two experiments and measure the time:\n","\n","1. Compute $\\|A B_{i\\cdot}\\|^2$ one at a time and assign its outcome to $\\mathbf{c}_i$ directly.\n","1. Use an intermediate storage vector $\\mathbf{d}$ in PyTorch for assignments and copy to NumPy at the end."]},{"cell_type":"code","metadata":{"id":"V6kn4JOw3Efg"},"source":["## Solution 1\n","torch.manual_seed(42)\n","A= torch.randn((10000, 10000),device=device)\n","B= torch.randn((10000,10000),device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBrS3OFpS5z9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118815802,"user_tz":300,"elapsed":39026,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"803e2959-df3e-4f96-aeef-9b0f938c8998"},"source":["## Solution 2a - One at a time\n","c=np.empty(10000)\n","start=time.time()\n","for i in range(10000):\n","  \n","  c[i] = torch.norm(torch.mv(A,B[:,i]))**2\n","\n","print(\" one at a time: \" + str(time.time()-start)+ \" seconds\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" one at a time: 38.762749433517456 seconds\n"]}]},{"cell_type":"code","metadata":{"id":"lbl6TeBbS61y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118853886,"user_tz":300,"elapsed":38100,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"e8a9b51e-3d46-41bb-90af-d1f4ea1cec07"},"source":["## Solution 2b - Copy to numpy at the end\n","d= torch.empty(10000,device=device)\n","start= time.time()\n","for i in range(10000):\n","  \n","  d[i]= torch.norm(torch.mv(A,B[:,i]))**2\n","\n","c= d.cpu().numpy()\n","print(\"convert at the end: \" + str(time.time()-start)+ \"seconds\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["convert at the end: 38.020729541778564seconds\n"]}]},{"cell_type":"markdown","metadata":{"id":"pW2DEN5x3Efj"},"source":["## Question 4. Memory efficient computation - 1.5 Point\n","\n","We want to compute $C \\leftarrow A \\cdot B + C$, where $A, B$ and $C$ are all matrices. Implement this in the most memory efficient manner. Pay attention to the following two things:\n","\n","1. Do not allocate new memory for the new value of $C$.\n","1. Do not allocate new memory for intermediate results if possible."]},{"cell_type":"code","metadata":{"id":"NRzN8HIv3Efj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118864053,"user_tz":300,"elapsed":228,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"a63fdb6f-b460-42c5-dcfc-051a0884e158"},"source":["A= torch.randn((1000, 1000),device=device)\n","B= torch.randn((1000,1000),device=device)\n","C= torch.randn((1000, 1000),device=device)\n","id(C)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["139687624700784"]},"metadata":{},"execution_count":327}]},{"cell_type":"code","metadata":{"id":"C6XC0d70acQ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118865763,"user_tz":300,"elapsed":287,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"33c5df6e-78db-4e42-a0fc-2ceeddf4c9e0"},"source":["# your code here\n","C += torch.mm(A, B)\n","id(C)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["139687624700784"]},"metadata":{},"execution_count":328}]},{"cell_type":"markdown","metadata":{"id":"8LV9o3GJ3Efp"},"source":["## Question 5. Broadcast Operations - 1.5 Point\n","\n","In order to perform polynomial fitting we want to compute a design matrix $A$ with \n","\n","$$A_{ij} = x_i^j$$\n","\n","Our goal is to implement this **without a single for loop** entirely using vectorization and broadcast. Here $1 \\leq j \\leq 3$ and $x = \\{1,2,3,4,5\\}$. Implement code that generates following A matrix\n","\n","$$\\begin{bmatrix} 1 & 1 & 1 \\\\ 2 & 4 & 8 \\\\ 3 & 9 & 27 \\\\ 4 & 16 & 64 \\\\ 5 & 25 & 125\\end{bmatrix}$$"]},{"cell_type":"code","metadata":{"id":"cAeYDuGC3Efq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118870143,"user_tz":300,"elapsed":235,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"0bf01b60-275f-4f9e-d7bd-80175cbf36f8"},"source":["# your code here\n","x = torch.arange(1, 6).reshape(5,1);\n","j = torch.arange(1, 4);\n","print(x ** j)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[  1,   1,   1],\n","        [  2,   4,   8],\n","        [  3,   9,  27],\n","        [  4,  16,  64],\n","        [  5,  25, 125]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"RX5yKE-t0sEn"},"source":["## Question 6. Numerical Precision - 2 Points\n","\n","Given scalars `x` and `y`, implement the following `log_exp` function such that it returns \n","$$-\\log\\left(\\frac{e^x}{e^x+e^y}\\right)$$."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.206890Z","start_time":"2019-01-29T22:48:56.202996Z"},"id":"bWMtemrU0sEn"},"source":["#Question\n","def log_exp(x, y):\n","    ## add your solution here and remove pass\n","   return -torch.log((torch.exp(x)) / (torch.exp(x) + torch.exp(y)))\n","   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2vnhIMm_0sEq"},"source":["Test your codes with normal inputs:"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.215579Z","start_time":"2019-01-29T22:48:56.209659Z"},"id":"OPTgyJUP0sEq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118875802,"user_tz":300,"elapsed":314,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"8e3ebadd-d894-430c-fefb-544368d51da8"},"source":["x, y = torch.tensor([2.0]), torch.tensor([3.0])\n","z = log_exp(x, y)\n","print(z)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.3133])\n"]}]},{"cell_type":"markdown","metadata":{"id":"WIxDzHy40sEu"},"source":["Now implement a function to compute $\\partial z/\\partial x$ and $\\partial z/\\partial y$ with `autograd`"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.223303Z","start_time":"2019-01-29T22:48:56.218056Z"},"id":"7EOGdkq_0sEu"},"source":["# function should print the gradients dx and dy \n","def grad(forward_func, x, y): \n","  x.requires_grad_()\n","  y.requires_grad_()\n","  ## Add your codes here\n","  #forward pass and backward pass\n","  f = forward_func(x,y)\n","  f.backward()\n","\n","  #return and print x and y gradients\n","  print(x.grad)\n","  print(y.grad)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ySyDOwxN0sEz"},"source":["Test your codes, it should print the results nicely. "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.267165Z","start_time":"2019-01-29T22:48:56.227035Z"},"id":"nT3QgbCB0sE0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118880648,"user_tz":300,"elapsed":5,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"8d36d3d8-2d16-42b3-8bfc-055b7e672a27"},"source":["grad(log_exp, x, y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.7311])\n","tensor([0.7311])\n"]}]},{"cell_type":"markdown","metadata":{"id":"fquEJMkU0sE2"},"source":["But now let's try some \"hard\" inputs"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.285842Z","start_time":"2019-01-29T22:48:56.274079Z"},"id":"MlDABmit0sE3"},"source":["x, y = torch.tensor([50.0]), torch.tensor([100.0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RwgzqhBmIoIi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118884396,"user_tz":300,"elapsed":258,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"32ba821d-34d0-46d7-a048-64797b2a07bb"},"source":["grad(log_exp, x, y) #gradient does not return correct results"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([nan])\n","tensor([nan])\n"]}]},{"cell_type":"code","metadata":{"id":"pXXpskJNByXD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118886139,"user_tz":300,"elapsed":310,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"8ad726a7-92f0-4d2a-b3f3-966722342f57"},"source":["torch.exp(torch.tensor([100.0])) #exp(100) returns an infinite tensor/overflow so above gradient does not return correct results"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([inf])"]},"metadata":{},"execution_count":336}]},{"cell_type":"markdown","metadata":{"id":"4O97Bv7y0sE6"},"source":["Does your code return correct results? If not, try to understand the reason. (Hint, evaluate `exp(100)`). Now develop a new function `stable_log_exp` that is identical to `log_exp` in math, but returns a more numerical stable result.\n","<br> Hint: (1) $\\log\\left(\\frac{x}{y}\\right) = log ({x}) -log({y})$\n","<br> Hint: (2) See logsum Trick - https://www.xarg.org/2016/06/the-log-sum-exp-trick-in-machine-learning/"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-01-29T22:48:56.305595Z","start_time":"2019-01-29T22:48:56.293399Z"},"id":"bzNFL9jG0sE6"},"source":["def stable_log_exp(x, y):\n","    ## Add your codes here)\n","    # -log(exp(x)) - -log(exp(x) + exp(y)) -> log(exp(x) + exp(y) )\n","    return torch.logaddexp(x,y)  - torch.logsumexp(x, -1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NVp9w2DKH-D_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631118944538,"user_tz":300,"elapsed":218,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"ab6725cd-f40d-496b-fd2a-00d14aab5c00"},"source":["grad(stable_log_exp, x, y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-1.])\n","tensor([1.])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ea_kC8Jy0sE8"},"source":["##  Question 7. Compute Gradient using  PyTorch Autograd - 1.5 Points\n","## $f(x,y) = \\frac{x + \\exp(y)}{\\log(x) + (x-y)^3}$\n","Compute dx and dy at x=3 and y=4"]},{"cell_type":"code","metadata":{"id":"XgW6W4CvONIs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631115765462,"user_tz":300,"elapsed":227,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"b8ed3889-b077-4bbf-f149-23d7c30e8c4a"},"source":["# your code here\n","x = torch.tensor([3.])\n","y = torch.tensor([4.])\n","\n","x.requires_grad_()\n","y.requires_grad_()\n","\n","forward = (x + torch.exp(y)) / (torch.log(x) + (x-y)**3)\n","forward.backward()\n","\n","dx = x.grad\n","dy = y.grad\n","\n","print(dx)\n","print(dy)\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-19733.3965])\n","tensor([18322.8477])\n"]}]},{"cell_type":"markdown","metadata":{"id":"DnMwwsfH7flN"},"source":["Let us check our solution using PyToch autodiff"]},{"cell_type":"markdown","metadata":{"id":"XRZm506z4ZOt"},"source":["## Bonus Question : Calculate the gradients manually without using PyTorch's Autograd. \n","- Break the function into simpler functions. Calculate the forward pass\n","- Use backward pass (chain rule) to calculate the gradients."]},{"cell_type":"code","metadata":{"id":"KLLClJEGWzXO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631038157277,"user_tz":300,"elapsed":102,"user":{"displayName":"Megan Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTsOGqJ8fUv53eluqr2pH6xh6CpHxDxlHFPrMVCg=s64","userId":"11419098456827326008"}},"outputId":"23810d80-fbe4-463b-ac8d-b6c60e380b8e"},"source":["#forward function breaking down the original function into smaller functions\n","a = None\n","b = None\n","\n","def f_intermediate(x, y):\n","  global a, b\n","  a = x + torch.exp(y)\n","  a.retain_grad()\n","  b = torch.log(x) + (x-y)**3\n","  b.retain_grad()\n","\n","  #final function\n","  z = a / b\n","  z.retain_grad()\n","  return z\n","\n","with torch.no_grad():\n","  dea = b \n","  deb = a \n","\n","  dax = torch.FloatTensor([1.0])\n","  dby = -3*(x-y)**2\n","  dbx = 3*(x-y)**2 + (1/x)\n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([584.0868], grad_fn=<DivBackward0>)"]},"metadata":{},"execution_count":22}]}]}